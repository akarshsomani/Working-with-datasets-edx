{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot') # Look Pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(model, X, y):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    padding = 0.6\n",
    "    resolution = 0.0025\n",
    "    colors = ['royalblue','forestgreen','ghostwhite']\n",
    "\n",
    "    # Calculate the boundaris\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Create a 2D Grid Matrix. The values stored in the matrix\n",
    "    # are the predictions of the class at at said location\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                       np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say?\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour map\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.terrain)\n",
    "\n",
    "    # Plot the test original points as well...\n",
    "    for label in range(len(np.unique(y))):\n",
    "        indices = np.where(y == label)\n",
    "        plt.scatter(X[indices, 0], X[indices, 1], c=colors[label], label=str(label), alpha=0.8)\n",
    "\n",
    "    p = model.get_params()\n",
    "    plt.axis('tight')\n",
    "    plt.title('K = ' + str(p['n_neighbors']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load up the dataset into a variable called `X`. Check `.head` and `dtypes` to make sure you're loading your data properly--don't fail on the 1st step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(\"Datasets/wheat.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry</th>\n",
       "      <th>groove</th>\n",
       "      <th>wheat_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>kama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   area  perimeter  compactness  length  width  asymmetry  groove  \\\n",
       "0   0  15.26      14.84       0.8710   5.763  3.312      2.221   5.220   \n",
       "1   1  14.88      14.57       0.8811   5.554  3.333      1.018   4.956   \n",
       "2   2  14.29      14.09       0.9050   5.291  3.337      2.699   4.825   \n",
       "3   3  13.84      13.94       0.8955   5.324  3.379      2.259   4.805   \n",
       "4   4  16.14      14.99       0.9034   5.658  3.562      1.355   5.175   \n",
       "\n",
       "  wheat_type  \n",
       "0       kama  \n",
       "1       kama  \n",
       "2       kama  \n",
       "3       kama  \n",
       "4       kama  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x.drop(['id'],axis=1,inplace=True)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "area           float64\n",
       "perimeter      float64\n",
       "compactness    float64\n",
       "length         float64\n",
       "width          float64\n",
       "asymmetry      float64\n",
       "groove         float64\n",
       "wheat_type      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the `wheat_type` series slice out of `X`, and into a series called `y`. Then drop the original `wheat_type` column from the `X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x['wheat_type']\n",
    "x.drop(['wheat_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>asymmetry</th>\n",
       "      <th>groove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.2210</td>\n",
       "      <td>5.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.6990</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.2590</td>\n",
       "      <td>4.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>5.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.4620</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.5860</td>\n",
       "      <td>5.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.0400</td>\n",
       "      <td>5.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>5.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>15.26</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>5.714</td>\n",
       "      <td>3.242</td>\n",
       "      <td>4.5430</td>\n",
       "      <td>5.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.7170</td>\n",
       "      <td>5.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>13.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.439</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.9860</td>\n",
       "      <td>4.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13.78</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>5.479</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.1360</td>\n",
       "      <td>4.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>13.74</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>5.482</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.9320</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>14.59</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>5.351</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4.1850</td>\n",
       "      <td>4.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>5.119</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.2340</td>\n",
       "      <td>4.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>15.69</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>5.527</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>5.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>14.70</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>5.205</td>\n",
       "      <td>3.466</td>\n",
       "      <td>1.7670</td>\n",
       "      <td>4.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>12.72</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>5.226</td>\n",
       "      <td>3.049</td>\n",
       "      <td>4.1020</td>\n",
       "      <td>4.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>14.16</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.0720</td>\n",
       "      <td>5.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>14.11</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>5.520</td>\n",
       "      <td>3.168</td>\n",
       "      <td>2.6880</td>\n",
       "      <td>5.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>15.88</td>\n",
       "      <td>14.90</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>5.618</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>5.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>12.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>5.099</td>\n",
       "      <td>2.936</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>4.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.76</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>5.789</td>\n",
       "      <td>3.245</td>\n",
       "      <td>1.7910</td>\n",
       "      <td>5.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>16.19</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.833</td>\n",
       "      <td>3.421</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>5.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>13.02</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>5.395</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.3730</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>5.395</td>\n",
       "      <td>2.956</td>\n",
       "      <td>2.5040</td>\n",
       "      <td>4.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>14.11</td>\n",
       "      <td>14.18</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>5.541</td>\n",
       "      <td>3.221</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>5.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>13.45</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>5.516</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.5310</td>\n",
       "      <td>5.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>11.41</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>5.090</td>\n",
       "      <td>2.775</td>\n",
       "      <td>4.9570</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>12.46</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.017</td>\n",
       "      <td>4.9870</td>\n",
       "      <td>5.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>12.19</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>5.240</td>\n",
       "      <td>2.909</td>\n",
       "      <td>4.8570</td>\n",
       "      <td>5.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>11.65</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>5.108</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.2090</td>\n",
       "      <td>5.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.77</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>5.495</td>\n",
       "      <td>3.026</td>\n",
       "      <td>6.1850</td>\n",
       "      <td>5.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>11.56</td>\n",
       "      <td>13.31</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.363</td>\n",
       "      <td>2.683</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>5.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>11.81</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.413</td>\n",
       "      <td>2.716</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>5.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>10.91</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.675</td>\n",
       "      <td>4.1790</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>11.23</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.821</td>\n",
       "      <td>7.5240</td>\n",
       "      <td>4.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>10.59</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>4.899</td>\n",
       "      <td>2.787</td>\n",
       "      <td>4.9750</td>\n",
       "      <td>4.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>10.93</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>5.046</td>\n",
       "      <td>2.717</td>\n",
       "      <td>5.3980</td>\n",
       "      <td>5.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>11.27</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>5.091</td>\n",
       "      <td>2.804</td>\n",
       "      <td>3.9850</td>\n",
       "      <td>5.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>11.87</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>5.132</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.5970</td>\n",
       "      <td>5.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>10.82</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>5.180</td>\n",
       "      <td>2.630</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>5.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>12.11</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>5.236</td>\n",
       "      <td>2.975</td>\n",
       "      <td>4.1320</td>\n",
       "      <td>5.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>12.80</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>5.160</td>\n",
       "      <td>3.126</td>\n",
       "      <td>4.8730</td>\n",
       "      <td>4.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>5.224</td>\n",
       "      <td>3.054</td>\n",
       "      <td>5.4830</td>\n",
       "      <td>4.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>13.37</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.320</td>\n",
       "      <td>3.128</td>\n",
       "      <td>4.6700</td>\n",
       "      <td>5.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>12.62</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>5.410</td>\n",
       "      <td>2.911</td>\n",
       "      <td>3.3060</td>\n",
       "      <td>5.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>12.38</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.989</td>\n",
       "      <td>5.4720</td>\n",
       "      <td>5.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>11.18</td>\n",
       "      <td>12.72</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>5.009</td>\n",
       "      <td>2.810</td>\n",
       "      <td>4.0510</td>\n",
       "      <td>4.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>12.70</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>5.183</td>\n",
       "      <td>3.091</td>\n",
       "      <td>8.4560</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>12.37</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>5.204</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.9190</td>\n",
       "      <td>5.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.6310</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.3250</td>\n",
       "      <td>5.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.3150</td>\n",
       "      <td>5.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.5980</td>\n",
       "      <td>5.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>209</td>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.6370</td>\n",
       "      <td>5.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   area  perimeter  compactness  length  width  asymmetry  groove\n",
       "0      0  15.26      14.84       0.8710   5.763  3.312     2.2210   5.220\n",
       "1      1  14.88      14.57       0.8811   5.554  3.333     1.0180   4.956\n",
       "2      2  14.29      14.09       0.9050   5.291  3.337     2.6990   4.825\n",
       "3      3  13.84      13.94       0.8955   5.324  3.379     2.2590   4.805\n",
       "4      4  16.14      14.99       0.9034   5.658  3.562     1.3550   5.175\n",
       "5      5  14.38      14.21       0.8951   5.386  3.312     2.4620   4.956\n",
       "6      6  14.69      14.49       0.8799   5.563  3.259     3.5860   5.219\n",
       "7      7  14.11      14.10       0.8911   5.420  3.302     2.7000     NaN\n",
       "8      8  16.63      15.46       0.8747   6.053  3.465     2.0400   5.877\n",
       "9      9  16.44      15.25       0.8880   5.884  3.505     1.9690   5.533\n",
       "10    10  15.26      14.85       0.8696   5.714  3.242     4.5430   5.314\n",
       "11    11  14.03      14.16       0.8796   5.438  3.201     1.7170   5.001\n",
       "12    12  13.89      14.02       0.8880   5.439  3.199     3.9860   4.738\n",
       "13    13  13.78      14.06       0.8759   5.479  3.156     3.1360   4.872\n",
       "14    14  13.74      14.05       0.8744   5.482  3.114     2.9320   4.825\n",
       "15    15  14.59      14.28       0.8993   5.351  3.333     4.1850   4.781\n",
       "16    16  13.99      13.83       0.9183   5.119  3.383     5.2340   4.781\n",
       "17    17  15.69      14.75       0.9058   5.527  3.514     1.5990   5.046\n",
       "18    18  14.70      14.21       0.9153   5.205  3.466     1.7670   4.649\n",
       "19    19  12.72      13.57       0.8686   5.226  3.049     4.1020   4.914\n",
       "20    20  14.16      14.40       0.8584   5.658  3.129     3.0720   5.176\n",
       "21    21  14.11      14.26       0.8722   5.520  3.168     2.6880   5.219\n",
       "22    22  15.88      14.90       0.8988   5.618  3.507     0.7651   5.091\n",
       "23    23  12.08      13.23       0.8664   5.099  2.936     1.4150   4.961\n",
       "24    24  15.01      14.76       0.8657   5.789  3.245     1.7910   5.001\n",
       "25    25  16.19      15.16       0.8849   5.833  3.421     0.9030   5.307\n",
       "26    26  13.02      13.76       0.8641   5.395  3.026     3.3730   4.825\n",
       "27    27  12.74      13.67       0.8564   5.395  2.956     2.5040   4.869\n",
       "28    28  14.11      14.18       0.8820   5.541  3.221     2.7540   5.038\n",
       "29    29  13.45      14.02       0.8604   5.516  3.065     3.5310   5.097\n",
       "..   ...    ...        ...          ...     ...    ...        ...     ...\n",
       "180  180  11.41      12.95       0.8560   5.090  2.775     4.9570   4.825\n",
       "181  181  12.46      13.41       0.8706   5.236  3.017     4.9870   5.147\n",
       "182  182  12.19      13.36       0.8579   5.240  2.909     4.8570   5.158\n",
       "183  183  11.65      13.07       0.8575   5.108  2.850     5.2090   5.135\n",
       "184  184  12.89      13.77       0.8541   5.495  3.026     6.1850   5.316\n",
       "185  185  11.56      13.31       0.8198   5.363  2.683     4.0620   5.182\n",
       "186  186  11.81      13.45       0.8198   5.413  2.716     4.8980   5.352\n",
       "187  187  10.91      12.80       0.8372   5.088  2.675     4.1790   4.956\n",
       "188  188  11.23      12.82       0.8594   5.089  2.821     7.5240   4.957\n",
       "189  189  10.59      12.41       0.8648   4.899  2.787     4.9750   4.794\n",
       "190  190  10.93      12.80       0.8390   5.046  2.717     5.3980   5.045\n",
       "191  191  11.27      12.86       0.8563   5.091  2.804     3.9850   5.001\n",
       "192  192  11.87      13.02       0.8795   5.132  2.953     3.5970   5.132\n",
       "193  193  10.82      12.83       0.8256   5.180  2.630     4.8530   5.089\n",
       "194  194  12.11      13.27       0.8639   5.236  2.975     4.1320   5.012\n",
       "195  195  12.80      13.47       0.8860   5.160  3.126     4.8730   4.914\n",
       "196  196  12.79      13.53       0.8786   5.224  3.054     5.4830   4.958\n",
       "197  197  13.37      13.78       0.8849   5.320  3.128     4.6700   5.091\n",
       "198  198  12.62      13.67       0.8481   5.410  2.911     3.3060   5.231\n",
       "199  199  12.76      13.38       0.8964   5.073  3.155     2.8280   4.830\n",
       "200  200  12.38      13.44       0.8609   5.219  2.989     5.4720   5.045\n",
       "201  201  12.67      13.32       0.8977   4.984  3.135     2.3000     NaN\n",
       "202  202  11.18      12.72       0.8680   5.009  2.810     4.0510   4.828\n",
       "203  203  12.70      13.41       0.8874   5.183  3.091     8.4560   5.000\n",
       "204  204  12.37      13.47       0.8567   5.204  2.960     3.9190   5.001\n",
       "205  205  12.19      13.20       0.8783   5.137  2.981     3.6310   4.870\n",
       "206  206  11.23      12.88       0.8511   5.140  2.795     4.3250   5.003\n",
       "207  207  13.20      13.66       0.8883   5.236  3.232     8.3150   5.056\n",
       "208  208  11.84      13.21       0.8521   5.175  2.836     3.5980   5.044\n",
       "209  209  12.30      13.34       0.8684   5.243  2.974     5.6370   5.063\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a quick, \"ordinal\" conversion of `y`. In actuality our classification isn't ordinal, but just as an experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.unique()\n",
    "y=y.replace('kama',1)\n",
    "y=y.replace('canadian',2)\n",
    "y=y.replace('rosa',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some basic nan munging. Fill each row's nans with the mean of the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 8 columns):\n",
      "id             210 non-null int64\n",
      "area           210 non-null float64\n",
      "perimeter      210 non-null float64\n",
      "compactness    210 non-null float64\n",
      "length         210 non-null float64\n",
      "width          210 non-null float64\n",
      "asymmetry      210 non-null float64\n",
      "groove         210 non-null float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 13.2 KB\n"
     ]
    }
   ],
   "source": [
    "x=x.fillna(x.mean(axis=0))\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of SKLearn's Normalizer class and then train it using its .fit() method against your _training_ data. The reason you only fit against your training data is because in a real-world situation, you'll only have your training data to train with! In this lab setting, you have both train+test data; but in the wild, you'll only have your training data, and then unlabeled data you want to apply your models to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "x=Normalizer().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just like your preprocessing transformation, create a PCA transformation as well. Fit it against your training data, and then project your training and testing features into PCA space using the PCA model's `.transform()` method. This has to be done because the only way to visualize the decision boundary in 2D would be if your KNN algo ran in 2D as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f1dfa0df550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "T=pca.transform(x)\n",
    "fig=plt.figure()\n",
    "plt.scatter(x=T[:,0],y=T[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `X` into training and testing data sets using `train_test_split()`. Use `0.33` test size, and use `random_state=1`. This is important so that your answers are verifiable. In the real world, you wouldn't specify a random_state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test,labels_train,labels_test=train_test_split(T,y,test_size=0.33,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your trained pre-processor, transform both your training AND testing data. Any testing data has to be transformed with your preprocessor that has ben fit against your training data, so that it exist in the same feature-space as the original data used to train your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train a KNeighborsClassifier. Start with `K=9` neighbors. Be sure train your classifier against the pre-processed, PCA- transformed training data above! You do not, of course, need to transform your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(data_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I hope your KNeighbors classifier model from earlier was named 'knn'\n",
    "# If not, adjust the following line:\n",
    "plotDecisionBoundary(model, data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the accuracy score of your test data/labels, computed by your KNeighbors model. You do NOT have to run `.predict` before calling `.score`, since `.score` will take care of running your predictions for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the ordinal conversion, try and get this assignment working with a proper Pandas get_dummies for feature encoding. You might have to update some of the `plotDecisionBoundary()` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
